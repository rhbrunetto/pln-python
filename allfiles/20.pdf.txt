IEEE TRANSACTIONS ON FUZZY SYSTEMS, VOL. 25, NO. 2, APRIL 2017

249

Multiobjective Evolutionary Optimization of Type-2

Fuzzy Rule-Based Systems for Financial

Data Classication

Michela Antonelli, Dario Bernardo, Hani Hagras, Fellow, IEEE, and Francesco Marcelloni, Member, IEEE

AbstractClassication techniques are becoming essential in the
nancial world for reducing risks and possible disasters. Managers
are interested in not only high accuracy, but in interpretability and
transparency as well. It is widely accepted now that the compre-
hension of how inputs and outputs are related to each other is
crucial for taking operative and strategic decisions. Furthermore,
inputs are often affected by contextual factors and characterized
by a high level of uncertainty. In addition, nancial data are usually
highly skewed toward the majority class. With the aim of achieving
high accuracies, preserving the interpretability, and managing un-
certain and unbalanced data, this paper presents a novel method
to deal with nancial data classication by adopting type-2 fuzzy
rule-based classiers (FRBCs) generated from data by a multiob-
jective evolutionary algorithm (MOEA). The classiers employ an
approach, denoted as scaled dominance, for dening rule weights in
such a way to help minority classes to be correctly classied. In par-
ticular, we have extended PAES-RCS, an MOEA-based approach
to learn concurrently the rule and data bases of FRBCs, for manag-
ing both interval type-2 fuzzy sets and unbalanced datasets. To the
best of our knowledge, this is the rst work that generates type-2
FRBCs by concurrently maximizing accuracy and minimizing the
number of rules and the rule length with the objective of producing
interpretable models of real-world skewed and incomplete nan-
cial datasets. The rule bases are generated by exploiting a rule and
condition selection (RCS) approach, which selects a reduced num-
ber of rules from a heuristically generated rule base and a reduced
number of conditions for each selected rule during the evolution-
ary process. The weight associated with each rule is scaled by the
scaled dominance approach on the fuzzy frequency of the output
class, in order to give a higher weight to the minority class. As
regards the data base learning, the membership function parame-
ters of the interval type-2 fuzzy sets used in the rules are learned
concurrently to the application of RCS. Unbalanced datasets are
managed by using, in addition to complexity, selectivity and speci-
city as objectives of the MOEA rather than only the classication
rate. We tested our approach, named IT2-PAES-RCS, on 11 nan-
cial datasets and compared our results with the ones obtained by
the original PAES-RCS with three objectives and with and with-
out scaled dominance, the FRBCs, fuzzy association rule-based

Manuscript received June 26, 2015; revised September 18, 2015 and January
21, 2016; accepted April 20, 2016. Date of publication June 8, 2016; date of
current version March 29, 2017.

M. Antonelli was with the Dipartimento di Ingegneria dellInformazione, Uni-
versity of Pisa, Pisa I-56100, Italy. She is now with the Centre for Medical Im-
age Computing, University College London, London WC1E 6BT, U.K (e-mail:
michela.antonelli@iet.unipi.it).

D. Bernardo and H. Hagras are with the Computational Intelligence Centre,
School of Computer Science and Electronic Engineering University of Essex,
Colchester CO43SQ, U.K. (e-mail: dariob@hotmail.com; hani@essex.ac.uk).
F. Marcelloni is with the Dipartimento di Ingegneria dellInformazione, Uni-
versity of Pisa, Pisa I-56100, Italy (e-mail: francesco.marcelloni@iet.unipi.it).

Digital Object Identier 10.1109/TFUZZ.2016.2578341

classication model for high-dimensional dataset (FARC-HD) and
fuzzy unordered rules induction algorithm (FURIA), the classical
C4.5 decision tree algorithm, and its cost-sensitive version. Using
nonparametric statistical tests, we will show that IT2-PAES-RCS
generates FRBCs with, on average, accuracy statistically compara-
ble with and complexity lower than the ones generated by the two
versions of the original PAES-RCS. Further, the FRBCs generated
by FARC-HD and FURIA and the decision trees computed by C4.5
and its cost-sensitive version, despite the highest complexity, result
to be less accurate than the FRBCs generated by IT2-PAES-RCS.
Finally, we will highlight how these FRBCs are easily interpretable
by showing and discussing one of them.

Index TermsFinancial datasets, multiobjective evolutionary
fuzzy systems, type-2 fuzzy rule-based classiers, unbalanced
datasets.

I. INTRODUCTION

T HE nancial crisis of 2008 demonstrated that lack of good

information can lead to disasters. Financial services orga-
nizations, customers, and particularly regulators quickly came
to understand that clear and relevant information was key to
risk reduction. Therefore, we are now witnessing ongoing ef-
forts by regulators to ensure that rms operating in nancial
services generate comprehensive and comprehensible informa-
tion. Supercially, the demands of regulators look burdensome.
In reality, however, they provide an opportunity for organiza-
tions to improve their strategic and operational activities through
risk reduction based on well-managed information [1].

Machine learning in nancial applications differs from other
domains in how the quality of a model is assessed. Whereas
in most applications, accuracy of prediction is often the only
metric used, in nancial applications, interpretability and trans-
parency are also important and sometimes a requirement. Within
nancial applications, the accuracy of the model is not the only
crucial issue. There is a growing interest in having high levels of
model transparency, which is the ability to provide a clear and
understandable explanation of the output result. If advanced
analytical techniques are used, there is now an obligation to
manage the whole process of creating and using the resulting
models. It is no longer enough to create a model, deploy it into
production, and leave it unattended without any oversight. A set
of capabilities and processes are required to ensure that every
aspect of model creation, deployment, and performance is well
understood, managed, and documented. This implies additional
technology infrastructure and methods, since in large rms, the

1063-6706  2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.

See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

250

IEEE TRANSACTIONS ON FUZZY SYSTEMS, VOL. 25, NO. 2, APRIL 2017

number of models in use might be measured in the thousands.
This represents a signicant shift to much greater sophistication
[1]. Another reason why it is important that we can understand
models is trust. A system that can explain why a certain deci-
sion was taken is more trustworthy in the eyes of a layman user.
This need for transparency is reected in legislation that forces
nancial institutions to disclose the reasoning behind their -
nancial decisions and models. Left unchecked, inevitably, there
will be rogue models that cause nancial harm and breach reg-
ulatory requirements [2]. Furthermore, transparency of a model
is important because it allows users to understand data associa-
tion by observing why a specic decision has been taken. This
process helps users to drill-down into their data, understand it,
and extract some useful knowledge that could be a competi-
tive advantage in the market. Ultimately, a transparent model
can become not only a tool for foresight and prediction, but for
analysis and domain knowledge extraction as well. As it is often
the case, managers in nance face two conicting demands. On
the one hand, they need to employ ever more powerful analyti-
cal techniques to remain competitive, while, on the other hand,
the models they use must be transparent and relatively easy to
explain [1][3].

Neural networks, Bayesian networks, and support vector ma-
chines are all considered black box. This adjective is applied
to systems that, for a given input, are able to output a class
label, but without providing a clear explanation of the decision
process. Logistic regression can provide some statistic correla-
tions between the inputs and the output, but this is not enough
to understand why, for a given input, a given label was chosen,
or to gain a deep insight of either the model or the data. On
the other hand, white box models usually refer to rule-based
systems that are able to provide an insight of the data on which
the models have been trained and an explanation of the decision
process through their rules. Decision trees can translate their
internal state into a set of rules and, like any other rule-based
system, are able to provide transparency. Nevertheless, in com-
plex real-world applications, such as in the nancial domain,
the number of generated rules can explode. It is debatable that
a rule base containing thousands of rules can be considered an
understandable and transparent model. Decision trees [4][6]
and random forests [7] produce associations among sets of data,
which are selected to optimize the classication problem. Thus,
the produced associations could be meaningless in the context
of proling and knowledge extraction.

Fuzzy logic extends the concepts of association rule learn-
ing by extending the rule antecedent sets to fuzzy concepts.
This technique, in conjunction with genetic and evolutionary
algorithms, is a powerful approach for creating accurate and
interpretable models. Studies such as [8][11] have shown that
accuracy and interpretability are in a tradeoff, and it is necessary
to sacrice one in order to increase the other. It is difcult to de-
ne to which extent accuracy or interpretability can be sacriced
in order to gain in the other. Usually, different applications and
specic situations have different requirements. Multiobjective
genetic algorithms are able to provide an evolution through the
two competitive objectives: accuracy and interpretability [12],
[13]. Such evolutionary algorithms generate a set of solutions,
also known as Pareto front, that optimize both objectives at

different levels. This feature gives the ability to easily identify
the desired level of complexity/accuracy for the specic appli-
cation. However, the vast majority of fuzzy systems employ the
type-1 fuzzy sets, which cannot directly handle the high levels
of uncertainty present in nancial applications. Indeed, type-1
fuzzy sets are crisp and precise (i.e., their membership functions
are supposed to be perfectly known) and do not allow for any un-
certainty about membership values, which is a liability for their
use. A type-2 fuzzy set is characterized by a fuzzy membership
function, i.e., the membership value for each element of this set
is itself a fuzzy set dened on the universe [0,1] [14]. The mem-
bership functions of the type-2 fuzzy sets are 3-D and include a
footprint of uncertainty. The third dimension and the footprint
of uncertainty provide additional degrees of freedom that make
it possible to directly model and handle the high level of uncer-
tainty affecting the inputs in nancial applications. In addition,
it should be noted that using type-2 fuzzy sets to represent the
system inputs can result in reduction of the fuzzy classier rule
base and complexity (as it will be shown in Section IV) when
compared with using type-1 fuzzy sets. Indeed, the footprint
of uncertainty, which characterizes the type-2 fuzzy sets, lets us
cover the same range as type-1 fuzzy sets with a smaller number
of labels: Of course, the rule reduction will be greater when the
number of inputs increases [14].

Previous works have already employed type-2 fuzzy classi-
ers in nancial domain [15][17] and have shown how these
systems outperform their type-1 versions and other state-of-
the-art classiers. However, to date, most of the type-2 fuzzy
systems reported in the literature have been generated from data
by optimizing only the accuracy, while neglecting the complex-
ity [17][23]. This aspect is of major importance to the nancial
domain since offering compact fuzzy classiers with the same
accuracy as their counterparts will help to realize transparent
and easy to understand models, which are becoming essential
requirements especially after the recent economic crisis.

In nancial applications, as in many real-world problems, the
data present challenges that are not often found in traditional
academic datasets. Some of these are: size, noise, sparsity, and
uncertainty. Furthermore, in the vast majority of nancial appli-
cations, data are highly unbalanced [24]. For example, in credit
card applications, the number of good customers is much higher
than that of bad customers, and in fraud detection, the major-
ity of the data is normal transactions with only a few fraudulent
transactions. Most classiers designed for minimizing the global
error rate perform poorly on unbalanced datasets, because they
misclassify most of the data belonging to the class with few
examples. To tackle this problem, preprocessing techniques like
undersampling or oversampling are usually applied, but both of
them present problems. On the one hand, undersampling tech-
niques may increment the noise, since they could eliminate some
important patterns. On the other hand, oversampling techniques
may add noise for the original input data or violate the inher-
ent geometrical structure of the minority and majority classes.
Hence, in nancial applications, it is not desirable to preprocess
or sample the data, as this could cause problems. Thus, there
is a need for predictive analytics techniques that can handle
unbalanced nancial datasets to give accurate and interpretable
nancial models.

ANTONELLI et al.: MULTIOBJECTIVE EVOLUTIONARY OPTIMIZATION OF TYPE-2 FUZZY RULE-BASED SYSTEMS

251

In this paper, with the aim of dealing with uncertain and unbal-
anced data and generating accurate and interpretable classiers,
we employ PAES-RCS [25], [26], a multiobjective evolution-
ary algorithm (MOEA)-based approach to learn concurrently
the rule and data bases of fuzzy rule-based classiers (FRBCs).
In PAES-RCS, the learning process is performed by selecting
a set of rules from an initial rule base and a set of conditions
for each selected rule. This scheme is denoted as rule and con-
dition selection (RCS). During the multiobjective evolutionary
process, PAES-RCS generates the rule bases of the classiers
by using the RCS approach and concurrently learns the mem-
bership function parameters of the linguistic values used in the
rules. The original PAES-RCS is extended so as to manage inter-
val type-2 (IT2) fuzzy sets and unbalanced datasets. We denote
this extension as IT2-PAES-RCS in the following. We modied
both the inference mechanism and the evolutionary process for
coping with the IT2 fuzzy sets. Further, we adopted three objec-
tives, namely false positive rate (FPR), true positive rate (TPR),
and complexity. In our previous works [27], we have veried
that the use of FPR and TPR as objectives of the evolutionary
optimization process has proved to be very effective in manag-
ing unbalanced datasets. Indeed, one of the main strengths of
IT2-PAES-RCS is that it can be applied to unbalanced datasets
without any rebalancing.

We tested IT2-PAES-RCS on 11 nancial datasets and
compared the results with the ones obtained by the origi-
nal PAES-RCS, employing FPR and TPR as objectives, with
(PAES-RCS-SD) and without scaled dominance, the FRBCs
fuzzy association rule-based classication model for high-
dimensional dataset (FARC-HD) [28] and fuzzy unordered rules
induction algorithm (FURIA) [29], the classical C4.5 decision
tree algorithm [30], and its cost-sensitive version (C4.5-CS)
[31]. Using nonparametric statistical tests, we will show that
IT2-PAES-RCS generates FRBCs with accuracy statistically
comparable with the ones generated by PAES-RCS and PAES-
RCS-SD, employing a lower number of rules and a lower num-
ber of conditions in the antecedent of the rules. The FRBCs
generated by IT2-PAES-RCS result, therefore, to be less com-
plex and more interpretable. Further, the FRBCs generated by
FARC-HD and FURIA, and the decision trees computed by C4.5
and its cost-sensitive version, despite the lowest interpretabil-
ity, result to be less accurate than the solutions generated by
IT2-PAES-RCS.

This paper is organized as follows. In Section II, we provide
a basic description of FRBCs based on IT2 fuzzy sets and intro-
duce some notations. Section III shows the proposed MOEA-
based learning approach and includes the details of the initial
rule base generation technique, of the chromosome coding and
mating operators, and of the adopted MOEA. In Section IV, we
illustrate the experimental results, and in Section V, we draw
some nal conclusion.

II. INTERVAL TYPE-2 FUZZY RULE-BASED CLASSIFIER

Object classication consists of assigning a class Cj from
a predened set {C1, . . . , CK } of classes to an object. Each
object is considered as an F-dimensional point in a feature
space (cid:2)F. Let X = {X1, . . . , XF } be the set of features

Fig. 1. Example of IT2 fuzzy partitions with Tf = 5 IT2 fuzzy sets (the
thick and thin lines represent the upper and lower membership functions,
respectively).

and Uf , f = 1, . . . , F , be the universe of the fth feature. Let
Pf = { Af ,1, , . . . , Af ,T f
}, f = 1, . . . F , be a fuzzy partition
with Tf IT2 fuzzy sets of the universe Uf . We recall that
an IT2 fuzzy set A is characterized by a fuzzy membership
function  A (x), that is, the membership value for each element
of this set is a fuzzy set [32]. The membership functions of IT2
fuzzy sets include a footprint of uncertainty, which provides
additional degrees of freedom that make it possible to directly
model and handle uncertainties. In the IT2 fuzzy sets, all the 3-D
values are equal to 1. More formally, the membership function
 A (x) of an IT2 fuzzy set A is dened as

(cid:4)

(cid:2)
xX

(cid:3)(cid:2)
u[ A

 A (x) =

1/u

/x

(1)

(x),  A (x) ]

a f , j +b f , j

where  A (x) and  A
(x) represent, respectively, the upper and
lower membership functions of the IT2 fuzzy set A. In this pa-
per, we use triangular membership functions dened by three
points (a, b, c), where a and c correspond to the endpoints of
the support and b to the core. We build the IT2 fuzzy sets by
using the following procedure. First, we dene the upper tri-
angular membership functions  A (x) through the three points
(af ,j , bf ,j , cf ,j ). Then, the left endpoints af ,j of the supports
(x) are computed as
of the lower membership functions  A f
between the left endpoints af ,j of the
midpoints
(x) and their
supports of the upper membership functions  A f
cores bf ,j . Similarly, the right endpoints cf ,j of the supports
(x) correspond to the
of the lower membership functions  A f
between the right endpoints cf ,j of the sup-
mid-points
(x) and the cores
ports of the upper membership functions  A f
bf ,j . It follows that af ,j = cf ,j1, for j = 2, . . . , Tf . The
cores bf ,j coincide with the cores bf ,j . Fig. 1 shows an example
of IT2 fuzzy partition with Tf = 5. Here, the upper member-
ship functions (thick lines) are obtained by dening a uniform
Ruspini partition with triangular membership functions on the
universe Uf .

b f , j + c f , j

2

2

252

IEEE TRANSACTIONS ON FUZZY SYSTEMS, VOL. 25, NO. 2, APRIL 2017

The mth rule Rm (m = 1, . . . , M) of an IT2 FRBC is typi-

cally expressed as

Rm: IF X1 is A1,jm, 1 and . . . and XF is AF ,jm, F

THEN Y is Cjm with RWm

(2)
where Y is the classier output, Cjm is the class label associated
with the mth rule, jm ,f  [1, Tf ] identies the index of the IT2
fuzzy set (among the Tf IT2 fuzzy sets of the partition P f ),
which has been selected for Xf in rule Rm , and RWm is the
rule weight, i.e., a certainty degree of the classication in the
class Cjm for a pattern that res the antecedent of the rule.
Let T = {(x1, y1), . . . , (xN , yN )} be a training set com-
posed of N input-output (xt, yt) pairs, with xt = [xt,1, . . . ,
xt,F ]  (cid:2)F and yt  {C1, . . . , CK }. The strength of activa-
tion wm (xt) (matching degree of the rule with the input) of the
rule Rm is calculated as

(3)

wm (xt) = wm (xt) + wm (xt)

2

(xt,f ) and wm (xt) =

(cid:5)F
f =1  A f

(cid:5)F
where wm (xt) =
f =1  A f
(xt,f ) are the lower and upper bounds of the strength of acti-
vation computed, respectively, on the lower and upper member-
ship functions. To take the dont care condition into account,
a particular IT2 fuzzy set Af ,0(f = 1, . . . , F ) is added to all
the F partitions Pf . This fuzzy set is characterized by both the
lower and upper membership functions equal to 1 on the over-
all universe. This means that the condition Xf is Af ,0 does
not affect the computation of the strength of activation. In other
words, for the specic rule, the variable Xf is not taken into
account and, therefore, can be removed. The terms Af ,0, there-
fore, allow generating rules, which contain only a subset of the
input variables, thus reducing the total rule length (TRL) and
consequently increasing the interpretability of the rules.

As we have pointed out in Section I, nancial data are usually
highly unbalanced. To give minority class a fair chance when
competing with majority class, we adopted a new approach to
calculate the rule weight that takes the fuzzy frequency of the
class into account. The approach is called scaled dominance
and has been introduced in [33][35]. In the literature, fuzzy
rule weights are traditionally calculated as fuzzy extension of the
condence and support. Condence and support are data mining
metrics used in association rule learning. These metrics, in fuzzy
rule-based systems, are extended by using fuzzy strength instead
of crisp counting of the item sets. The condence and support
extensions used in this paper exploit a scaled version ws
m of
the matching degree. For a given rule Rm , having a consequent
class Cjm , we scale the matching degree of the rule by dividing
the upper and lower bounds of the strengths of activation by the
sum of, respectively, the upper wl(xt) and lower wl(xt) bounds
of the strengths of activation of all the rules Rl, which have Cjm
as the consequent class. The scaled upper and lower bounds are,
therefore, computed as follows:
(cid:6)
(cid:6)

ws
m (xt) =

wm (xt)

wm (xt)

wl (xt)

l,ou t= C j m

(4)

ws

m (xt) =

(5)

l,ou t= C j m

w l (xt) .

In IT2 fuzzy rule-based systems, condence and support of
a rule are determined from the strength of activation and, there-
fore, dened by upper and lower bounds. From (4) and (5),
we derive the following scaled upper and lower bounds of the
condence:

m (Antm  Cjm
cs

) =

m (Antm  Cjm
cs

) =

(cid:6)
(cid:6)M
ws
m (xt)
x t C j m
(cid:6)
m (xt)
m =1 ws
(cid:6)M
m (xt)
ws
x t C j m
m (xt)
m =1 ws

(6)

(7)

where M is the number of rules in the rule base, and Antm is the
antecedent of Rm . The condence can be viewed as a numerical
|Antm ).
approximation of the conditional probability P (Cjm
The scaled upper and lower bounds of the support are dened
as

m (Antm  Cjm
ss

) =

m (Antm  Cjm
ss

) =

(cid:6)
x t C j m
(cid:6)
M
x t C j m
M

ws
m (xt)

ws

m (xt)

(8)

(9)

.

The support can be viewed as a measure of the coverage of

training patterns performed by Rm .

The rule weight is then calculated as product of the scaled
condence and support. It follows that the rule weight RWm in
(2) becomes a closed interval bounded by the upper RW m and
RW m endpoints, calculated as

RW m = cs
RW m = cs

m  ss
m  ss

m

m

(10)

(11)

The association degree with the class Cjm will be, in its
turn, a closed interval bounded by the upper hm (xt) and lower
h m (xt) endpoints, which are computed as follows:

hm (xt ) = ws

= ws

(cid:6)

(cid:6)

ws

m (xt )

x t C j m
M

=

ws

h m (xt ) = ws

= ws

ws

m (xt )

x t C j m
M

= ws





m (xt )  RW m
(cid:6)
ws
m (xt )
(cid:6)M
x t C j m
m (xt ) 
m = 1 ws
m (xt )
(cid:7)(cid:6)
ws
m (xt )
(cid:6)M
x t C j m
m (xt )
m = 1 ws
m (xt )
M
m (xt )  RW m
(cid:6)
(cid:6)M
x t C j m
m (xt ) 
m = 1 ws
(cid:7)(cid:6)
(cid:6)M
x t C j m
m = 1 ws

m (xt )
ws
m (xt )

m (xt )
ws
m (xt )

m (xt )
M





(cid:8)2

(12)

(cid:8)2

.

(13)

We adopt

the maximum matching method as reasoning
method: An input pattern is classied into the class correspond-
ing to the rule with the maximum association degree calculated
for the pattern. In the case of tie, we randomly classify the
pattern. The association degree for rule Rm is computed as

hm (xt) =

hm (xt) + h m (xt)

2

.

(14)

ANTONELLI et al.: MULTIOBJECTIVE EVOLUTIONARY OPTIMIZATION OF TYPE-2 FUZZY RULE-BASED SYSTEMS

253

Once xed the number Tf of IT2 fuzzy sets for each linguistic
variable, we adopt an MOEA-based approach to learn rules and
membership function parameters so as to generate a set of IT2
FRBCs with different tradeoffs between accuracy and rule base
complexity.

III. PROPOSED THREE OBJECTIVE EVOLUTIONARY

OPTIMIZATION OF INTERVAL TYPE-2 FUZZY

RULE-BASED CLASSIFIERS

MOEAs have been applied in several different domains to
search for optimal solutions to problems characterized by mul-
tiple performance criteria in competition with each other [36].
MOEAs do not generate a unique solution, but rather a set of
equally valid solutions, where each solution tends to fulll a
criterion to a higher extent than another. Comparison between
different solutions is performed by using the notion of Pareto
dominance. A solution x, associated with a performance vector
u, dominates a solution y, associated with a performance vector
v, if and only if,  i  {1, . . . , I}, with I the number of criteria,
ui performs better than, or equal to, vi and i  {1, . . . , I},
such that ui performs better than vi, where ui and vi are the ith
elements of vectors u and v, respectively. The set of solutions,
which are not dominated by any other possible solution, is de-
noted as Pareto front. The objective of any MOEA is, therefore,
to search for a set of solutions that are a good approximation
of the Pareto front. In the last years, in designing fuzzy rule-
based systems, developers have not only considered accuracy,
but also interpretability as a crucial requirement. Since accu-
racy and interpretability are objectives in competition with each
other, MOEAs have been so extensively applied that the term
multiobjective evolutionary fuzzy system has been coined to
identify fuzzy rule-based systems generated by MOEAs [12],
[13], [37], [38]. While the accuracy objective has been typically
measured in terms of classication rate and approximation er-
ror for, respectively, classication and regression problems, a
number of specic measures have been proposed for evaluating
the interpretability, taking the rule base complexity and the data
base integrity into account [39], [40]. A large number of con-
tributions have been recently published under the framework
of multiobjective evolutionary fuzzy systems, with application
mostly to regression [41][58] problems. Recently, some tax-
onomies of the main contributions have been also introduced in
[12] and [13].

In this paper, we extend PAES-RCS, a multiobjective evolu-
tionary fuzzy system that has been recently proposed by some of
the authors of this paper in [25] and [26]. PAES-RCS has proved
to be very effective and efcient in classication problems [26].
The original PAES-RCS learns concurrently the rule and data
bases of type-1 FRBCs by exploiting the RCS approach, which
selects a reduced number of rules from a heuristically generated
rule base and a reduced number of conditions for each selected
rule during the evolutionary process. Thus, RCS can be consid-
ered a sort of rule learning in a search space constrained by the
heuristically generated rule base. The membership function pa-
rameters of the type-1 fuzzy sets are learned concurrently to the
application of RCS. This requires an appropriate chromosome
coding and properly dened mating operators. In particular,

chromosome C consists of two parts (CR B , CDB ), which dene
the rule base and the membership function parameters of the
input variables, respectively. Both crossover and mutation oper-
ators are applied to each part of the chromosome independently.
The objectives used in PAES-RCS are classication rates and
complexity measured in terms of the total number of antecedent
conditions of the rules in the rule base.

In this paper, we extend PAES-RCS along three directions.
First of all, we employ IT2 fuzzy sets rather than type-1 fuzzy
sets. This has required the adoption of a different inference
mechanism. Second, in order to cope with unbalanced datasets,
we split the accuracy into two objectives, namely TPR and
FPR. We recall that TPR and FPR coincide, respectively, with
the sensitivity and the complement to 1 of the specicity. As
experimented in [27] and [37] using rule learning, this approach
allows achieving high accuracies when dealing with unbalanced
datasets without needing to rebalance the dataset. Third, we use
an approach denoted as scaled dominance, which was intro-
duced in [33][35], to handle unbalanced data by trying to give
minority classes a fair chance when competing with a majority
class. This improvement further contributes to manage unbal-
anced data.

In the following subsections, we will discuss the method to
generate the initial rule base and summarize the RCS approach
and the membership function parameter learning used in IT2-
PAES-RCS.

A. Initial Rule Base Generation

We generate the initial rule base by rst transforming each
continuous variable into a categorical and ordered variable.
Then, we apply the well-known C4.5 algorithm to the trans-
formed dataset for generating a decision tree. Finally, we extract
the initial rule base from the decision tree.
More precisely, for each continuous variable Xf , rst, we
generate an IT2 fuzzy partition Pf = { Af ,1, , . . . , Af ,T f
} of
Tf IT2 fuzzy sets, as shown in Fig. 1. The number Tf of IT2
fuzzy sets can be different from an input variable to another.
For the sake of simplicity, in our experiments, we have used
the same number of IT2 fuzzy sets for all the variables Xf .
Then, we compute the -cut, with  = 0.5, of the fuzzy sets
dened by the upper membership functions  Af ,j of the IT2
fuzzy sets Af ,j , j = 1, . . . , Tf . The corresponding contiguous
intervals, shown in Fig. 2, are used to discretize the universe
Uf of each variable Xf before applying the C4.5 algorithm.
For simplicity, we will denote the intervals with the index of
the corresponding IT2 fuzzy set, which the -cut is applied to.
For instance, interval 1 denotes the interval corresponding to
the -cut of the fuzzy set dened by  Af ,1 . Then, each input
value of the inputoutput pairs in the training set is replaced
by the interval, which contains it. Thus, the overall training set
is transformed so as to contain exclusively categorical values.
Finally, we apply the classical C4.5 algorithm to the transformed
training set. We extract the initial rule base from the decision tree
generated by the C4.5 algorithm. Rules are extracted from each
path from the root to a leaf node. Each splitting criterion along a
given path is logically ANDed to form the rule antecedent (IF
part). The leaf node holds the class prediction, forming the rule

254

IEEE TRANSACTIONS ON FUZZY SYSTEMS, VOL. 25, NO. 2, APRIL 2017

Fig. 2. Discretization of the universe Uf based on an IT2 fuzzy partition
(the thick and thin lines represent the upper and lower membership functions,
respectively; the dashed lines denote the boundaries of the intervals generated
by the -cut).

Fig. 4.

Fuzzy rule base extracted from the decision tree shown in Fig. 3.

Fig. 5. Example of the CRB part of a chromosome.

the set of MC 45 rules extracted from the decision tree, and
vm = [vm,1, . . . , vm,F ] is a binary vector, which indicates, for
each condition in the rule, if the condition is present (vm ,f = 1)
or corresponds to a dont care (vm ,f = 0). Rule bases gener-
ated by the C4.5 algorithm could include a high number of rules,
especially when dealing with large and high-dimensional train-
ing sets. With the aim of obtaining compact and interpretable
FRBCs, we have set an upper bound Mmax to the number of
rules that can be contained in any rule base generated dur-
ing the evolutionary process. In the experiments, we have set
Mmax = 50. In our previous works [26], we have veried that
this value permits us to generate FRBCs with reasonable ac-
curacy, maintaining the complexity at an adequate level. Let
MC 45 be the number of rules extracted from the decision tree.
If MC 45 < Mmax, then Mmax = MC 45. During the evolution-
ary process, the MOEA can generate rule bases, which contain
a number of rules lower than Mmax. Indeed, if km = 0, then the
mth rule is not included in the rule base. Further, the number of
conditions can be lower than the number F of features. Indeed,
if vm,f = 0, then the fth condition of the mth rule is replaced
by a dont care condition and, therefore, is not considered in
the inference process. Whenever a condition selection is per-
formed on the rule, the rule weight associated with the rule is
recomputed.

As an example, given a two input fuzzy model, let us assume
that the C4.5 algorithm has generated the following four rules:

R1: IF X1 is A1,1 and X2 is A2,1 THEN Y is C1
R2: IF X1 is A1,2 and X2 is A2,2 THEN Y is C2
R3: IF X1 is A1,5 and X2 is A2,3 THEN Y is C1
R4: IF X2 is A2,1 THEN Y is C1.
Let us suppose that, during the evolutionary process executed
with Mmax = 3, the CRB chromosome part shown in Fig. 5 is
generated.

The rst gene of the chromosome selects rule R2 (k1 is equal
to 2) with all the conditions (both v1,1 and v1,2 are equal to 1).

Fig. 3. Example of decision tree generated by the C4.5 algorithm applied to
the transformed training set.

consequent (THEN part). Since each branch is identied by
one of the intervals determined by the discretization process and
an input variable is involved in just one node in a path, the rules
extracted from the decision tree are expressed as in (2). Each
rule is identied by an integer from 1 to MC 45, where MC 45 is
the number of rules extracted from the tree and included in the
initial rule base.

Fig. 3 shows an example of a decision tree generated by
the C4.5 algorithm from a training set characterized by six in-
put variables and two classes (C1, C2). Each input variable
Xf , f = 1, . . . , 6, has been partitioned with Tf = 5 fuzzy sets.
We observe that only three out of the six original input variables
are included in the decision tree. This is due to the well-known
characteristic of the C4.5 algorithm that can select features dur-
ing the generation of the tree. Fig. 4 shows the rule base extracted
from the decision tree of Fig. 3. We note that the rule base con-
sists of 13 rules, which correspond to the 13 possible paths from
the root to the leaf nodes.

B. Rule and Condition Selection

The CRB part of the chromosome is a vector of Mmax pairs
pm = (km , vm ), where km identies the index of the rule in

ANTONELLI et al.: MULTIOBJECTIVE EVOLUTIONARY OPTIMIZATION OF TYPE-2 FUZZY RULE-BASED SYSTEMS

255

Fig. 6. CD B part of a chromosome.

The second gene selects rule R3 (k2 is equal to 3) with only
the rst condition (v2,1 is equal to 1, while v2,2 is equal to 0).
The third gene selects no rule (k3 is equal to 0).

The rule base corresponding to the chromosome in Fig. 5

will, therefore, be

R2: IF X1 is A1,2 and X2 is A2,2 THEN Y is C2
R3: IF X1 is A1,5 THEN Y is C1.
We note that, even though Mmax = 3, only two rules have
been selected in the nal rule base. Furthermore, for the third
rule, only the rst condition has been selected.

The CDB part of the chromosome codies the upper mem-
bership functions of each variable Xf . Since the lower mem-
bership functions are built, as described in Section II, from
the upper membership functions, the CDB part codies ex-
clusively these functions. Since we adopt strong fuzzy parti-
tions for dening the upper membership functions with, for
j = 2, . . . , Tf  1, bf ,j = cf ,j1 and bf ,j = af ,j+1, each trian-
gular fuzzy set (af ,j , bf ,j , cf ,j ) of the partition is completely de-
ned by xing the positions of the cores bf ,j along the universe
Uf of the fth variable (we normalize each variable in [0,1]).
Since bf ,1 and bf ,T f coincide with the lower and upper extremes
of universe Uf , the partition of each linguistic variable Xf is
completely dened by Tf  2 parameters {bf ,2, . . . , bf ,T f 1},
which dene the positions of the cores of the upper member-
ship functions dened on Xf . As shown in Fig. 6, the CDB
chromosome part, therefore, consists of F vectors of Tf  2
real numbers. A good level of integrity, in terms of order, cov-
erage, and distinguishability, of the partitions is ensured by,
j  [2, Tf  1], forcing bf ,j to vary in the denition interval
[bf ,j  b f , j b f , j 1

, bf ,j + b f , j + 1 b f , j

2

].

2

Fig. 7. Application scheme of the genetic operators.

The mutation operator applied to CDB , rst, randomly
chooses an input variable Xf , f  [1, F ], and a fuzzy set
j  [2, Tf  1] and then replaces the value of bf ,j with a value
randomly chosen within the denition interval of bf ,j .

If, after applying the crossover, the rule base contains one or
more pairs of equal rules, we simply eliminate one of the rules
from each pair setting the corresponding km to zero.

D. Multiobjective Evolutionary Algorithm

The MOEA used in this paper is the (2 + 2)M-PAES algo-
rithm proposed in [41] and adopted in [26]. The application
scheme of the crossover and mutation operators employed in
(2 + 2)M-PAES for generating the offspring solutions o1 and
o2 from the current solutions s1 and s2 is shown in Fig. 7. Here,
PCRB , PCDB , PMRB 1, and PMRB 2 represent the probabilities of
applying the crossover operators to CRB and CDB parts and the
rst and the second mutation operators to CRB , respectively.
PMDB represents the probability of applying the mutation op-
erator to CDB . Unlike classical (2 + 2)PAES, which maintains
the current solutions s1 and s2 until they are not replaced by
solutions with particular characteristics, we observe that in (2 +
2)M-PAES s1 and s2 are randomly extracted at each iteration.
At the beginning, we generate two current solutions s1 and
s2. While the genes of the CDB part and the km values of the
CRB part of s1 and s2 are randomly generated, all the values
vm,f of the conditions of all the rules are set to 1. An offspring
solution ox is added to the archive only if it is dominated by
no solution contained in the archive; possible solutions in the
archive dominated by ox are removed. If the archive is full and
no solution in the archive can be removed, then the offspring so-
lution ox is inserted into the archive and the solutions (possibly
ox itself), which belong to the region with the highest crowding
degree, are removed. If the region contains more than one so-
lution, then, the solution to be removed is randomly chosen.

C. Genetic Operators

Both crossover and mutation operators are employed to gen-
erate the offspring population. In particular, we apply the one-
point crossover to the CRB part and the BLX- crossover, with
 = 0.5, to the CDB part. In applying the one-point crossover,
the common gene between the two mating chromosomes s1 and
s2 is determined by extracting randomly a number in [1, MAX ],
where MAX is the maximum number of rules in s1 and s2. The
crossover point is always chosen between two rules and not
within a rule.

As regards mutation, two operators are applied to the CRB
part. Both the operators randomly choose a pair pm , i.e., a rule,
in the chromosome. Then, the rst operator replaces the rule in
pm with another rule by setting km to an integer value randomly
generated in [1, MC 45].

The second operator modies the rule in pm by complement-
ing each gene vm,f with a probability equal to Pcond (Pcond = 2/f
in the experiments).

256

IEEE TRANSACTIONS ON FUZZY SYSTEMS, VOL. 25, NO. 2, APRIL 2017

TABLE I

FINANCIAL DATASETS USED IN THE EXPERIMENTS

(SORTED FOR INCREASING IRS)

Dataset

#Instances

#Attributes

IR

BLA
CARD
AF
ARB
COMM
SL
LEN
DPKG
BAN
GIV
COI

1747

176 463

1894
1641
16 102
35 798
24 772
72 983
45 211
150 000

9823

42
66
121
7
83
63
20
23
13
10
85

1.47
1.59
2.50
3.09
3.34
4.16
4.50
7.20
7.54
13.96
15.79

(2 + 2)M-PAES concurrently optimizes three objectives,
namely FPR, TPR and complexity. The complexity is measured
as the sum of the conditions, which compose the antecedents of
the rules in the rule base. This number is denoted as TRL. Low
values of TRL correspond to rule bases characterized by a low
number of rules and a low number of input variables really used
in each rule.

IV. EXPERIMENTS AND RESULTS

We analyzed 11 nancial datasets. For each dataset, we per-
formed a tenfold cross-validation and executed three trials for
each fold with different seeds for the random function genera-
tor (30 trials in total). We xed 50 000 evaluations as stopping
criteria.

In the following, we rst describe the nancial datasets. Then,
we show the results obtained by IT2-PAES-RCS, PAES-RCS,
PAES-RCS-SD, FARC-HD, FURIA, C4.5, and its cost-sensitive
version C4.5-CS. Finally, we analyze the results along accuracy
and interpretability dimensions.

A. Financial Datasets

In nancial applications, as in many real-world problems, the
data are highly unbalanced. For example, in a credit card appli-
cation, the number of good customers is much higher than that
of bad customers; in fraud detection, the majority of the data
are normal transactions whereas a few fraudulent transactions
are usually present. Most classiers designed for minimizing the
global error rate perform poorly on unbalanced datasets because
they misclassify most of the data belonging to the class repre-
sented by few examples. Hence, in our experiments, in order to
evaluate the proposed system for various nancial applications,
we have chosen 11 datasets with various sizes and different lev-
els of imbalance ratios (IRs) between the minority and majority
classes. The chosen datasets cover different nancial applica-
tions, including credit card and loan authorization, stock market
related predictions, insurance, fraud detection, and investment
banking.

We have used 11 real-world datasets from various nancial
domains. Table I summarizes the main characteristics of these
datasets. For each dataset, we report the name, the number of

instances (#Instances), the number of attributes (#Attributes),
and the IR. We recall that IR is dened as the ratio between the
number of instances of the majority class and of the minority
class. The datasets are sorted for increasing IRs. We do not
show the number of classes because all the datasets represent
two class problems.

In the following, we shortly describe each nancial dataset.
1) BLA: The dataset is related to the prediction of good
(protable) or bad (nonprotable) customers for bank
loan authorization.

2) CARD: The dataset is used to evaluate if a customer is

going to default on a credit card or no.

3) AF: The dataset is related to investment banking and is
used to predict if customers are going to pay back their
loans or if they will default on the given loan.

4) ARB: The dataset is used for spotting arbitrage oppor-
tunities in the London International Financial Futures
Exchange (LIFFE) market. The dataset was developed
in [4][6] to identify arbitrage situations by analyzing
option and futures prices in the LIFFE market.

5) COMM: The dataset is used for the evaluation of cus-
tomers (Fraud or No Fraud customer) for commercial
loans applications.

6) SL: The dataset is used for the evaluation of customers
(good or bad customers) for personal small loans appli-
cations where there is no knowledge on the customer full
credit history.

7) LEN: The dataset is used for evaluation of small compa-
nies (good or bad customer) for business loans applica-
tions when the customer full credit history is known.

8) DPKG: The dataset is used to predict whether in an

auction, the customer will be real or fraud.

9) BAN: The dataset is used to predict if a customer is
eligible for increasing the credit limits on her/his credit
cards.

10) GIV: The dataset is used to predict whether an applicant
is eligible to give her/him extra credit on her/his existing
loan or not.

11) COI: The dataset is used to predict whether a customer

will buy a caravan insurance or not.

B. Classiers

In this section, we shortly describe the classiers applied
to the nancial datasets. IT2-PAES-RCS was widely discussed
in Section III. The PAES-RCS algorithm used in this paper is
slightly different from the original version. Indeed, to manage
unbalanced datasets, we use three objectives as in IT2-PAES-
RCS, but generate type-1 FRBCs. PAES-RCS-SD is the version
of PAES-RCS with three objectives and with the scaled domain
approach.

FARC-HD was introduced in [28] and is a single-objective
evolutionary fuzzy classier, which exploits association rules
mining for generating FRBCs. FARC-HD is based on three
stages. First, it mines all possible fuzzy association rules build-
ing a search tree to list all frequent fuzzy item sets, limiting
the depth of the branches in order to nd a small number of
short fuzzy rules. Second, it uses a pattern weighting scheme

ANTONELLI et al.: MULTIOBJECTIVE EVOLUTIONARY OPTIMIZATION OF TYPE-2 FUZZY RULE-BASED SYSTEMS

257

to reduce the number of candidate rules, preselecting the most
interesting rules, in order to decrease the computational costs
for the third step. Finally, a single-objective genetic algorithm,
namely CHC, is used to select and tune a compact set of fuzzy
association rules. FRBCs generated by FARC-HD use the cer-
tainty factor and the additive combination [59] as rule weight
and reasoning method, respectively.

FURIA is an extension of the RIPPER algorithm [60]. Given
a classication problem with K classes, prior to the learning pro-
cess, RIPPER sorts the training data by class label in ascending
order according to the corresponding class frequencies. Then,
rules are learned for the rst K  1 classes, starting with the
least frequent. Once a rule has been generated, the instances
covered by that rule are removed from the training data, and
this is repeated until no instance from the target class is left.
The algorithm then proceeds with the next class. Finally, when
RIPPER nds no more rules to learn, a default rule (with empty
antecedent) is added for the last (and hence most frequent) class.
To learn each rule, the training set is split into a growing set and
a pruning set: the former is used to specialize the rule by adding
antecedents, while the latter is used to generalize the rule by
removing antecedents. FURIA extends RIPPER along three di-
rections: 1) the use of fuzzy rather than crisp rules, employing
fuzzy intervals with trapezoidal membership functions instead
of crisp intervals; 2) the exploitation of unordered rather than or-
dered rule sets; and 3) the introduction of a novel rule stretching
method in order to manage uncovered examples.

C4.5 builds decision trees from a set of training data using
the concept of information entropy. At each node of the tree, the
C4.5 algorithm chooses one attribute of the training set that most
effectively splits its set of samples into subsets enriched in one
class or the other. The splitting criterion is the normalized infor-
mation gain that results from choosing an attribute for splitting
the data. The attribute with the highest normalized information
gain is chosen to make the decision. The cost-sensitive version
of C4.5, denoted as C4.5-CS, exploits an instance weighting
method similar to the one adopted in the boosting decision tree
approach developed by Quinlan [61]. C4.5-CS changes the class
distribution so that the induced tree is in favor of the class with
high weight/cost. Thus, this version of the C4.5 is less likely to
commit errors with high costs.

Before applying FARC-HD, FURIA, and C4.5, the datasets
are preprocessed by using the synthetic minority oversampling
technique (SMOTE) [62]. In SMOTE, the minority class is over-
sampled by taking each minority class sample and introducing
synthetic examples along the line segments joining any or all
of the k minority class nearest neighbors. Depending upon the
amount of oversampling required, neighbors from the k-nearest
neighbors are randomly chosen.

Table II shows the parameters used for IT2-PAES-RCS,
PAES-RCS, and PAES-RCS-SD. The values of the parame-
ters come, on the one side, from the long experience we mat-
urated in the application of (2 + 2)M-PAES for generating
fuzzy rule-based systems since our initial paper on this subject
[41]. On the other side, we performed a number of experiments
with different values of these parameters using the datasets in
Table I and realized that the parameters in Table II are effective

VALUES OF THE PARAMETERS USED IN THE EXPERIMENTS FOR

IT2-PAES-RCS, PAES-RCS, AND PAES-RCS-SD

TABLE II

AS
T f
M m a x
P C R B
P C D B
P M R B 1
P M R B 2
P M D B

(2 + 2)M-PAES archive size
Number of fuzzy sets for each variable X f , f = 1, . . . , F
Maximum number of rules in a rule base
Probability of applying the crossover operator to C R B
Probability of applying the crossover operator to C D B
Probability of applying the rst mutation operator to C R B
Probability of applying the second mutation operator to C R B
Probability of applying the mutation operator to C D B

128
5
50
0.4
0.5
0.1
0.6
0.2

also for these datasets. For the other algorithms, we adopted the
implementation in Keel [63] and the default parameters.

C. Analysis of the Results

The execution of IT2-PAES-RCS, PAES-RCS, and PAES-
RCS-SD generates a set of solutions with different tradeoffs
among the three objectives. At the end of each execution of the
algorithms, we veried that the archive of (2 + 2)M-PAES is
always full for each dataset in Table I. Thus, each execution of
the three algorithms generates 128 different FRBCs. In order to
analyze the results of IT2-PAES-RCS, PAES-RCS, and PAES-
RCS-SD, each 3-D Pareto front approximation is projected onto
the FPR-TPR plane: Each FRBC of the Pareto front approxima-
tion is, therefore, represented as a point corresponding to the pair
(FPR, TPR). We recall that one classier in the FPR-TPR plane
is better than (dominates) another if it is located more north-west
(higher TPR and/or lower FPR) than the other [64]. For this rea-
son, in order to select a set of potentially optimal FRBCs, we
extract the nondominated solutions obtained on the training set
in the FPR-TPR plane. Since we do not assume to use any cost
function for selecting a single optimal classier, we consider
all the non-dominated solutions in the FPR-TPR plane. With
the aim of comparing the outputs of the three multiobjective
evolutionary approaches among them and with the other algo-
rithms, for each nondominated solution, we calculate the area
under the curve (AUC), dened as AU C = 100 + T P R  F P R
,
and select the solution with the highest AUC on the training
set. The highest AUC identies the most NorthWest solution
in the FPR-TPR plane. Thus, for each comparison algorithm,
we consider just one classier and compare these classiers in
terms of AUC computed on the test set.

2

Table III shows, for each dataset, the average AUC, FPR, and
TPR on both the training and the test sets, the average number
of rules, and the average TRL for the classiers with the highest
AUC on the training set generated by IT2-PAES-RCS, PAES-
RCS, and PAES-RCS-SD, and for the classiers generated by
FARC-HD, FURIA, C4.5, and C4.5-CS. For each dataset, we
have shown in bold the best values. We can observe that C4.5
and C4.5-CS suffer very much from overtraining. Indeed, the
value of the AUC is very high on the training set, but is quite low
on the test set. Although it is less evident than for C4.5 and C4.5-
CS, also FURIA suffers from overtraining: the AUC computed
on the test set is at least for some datasets much lower than on the
training set. IT2-PAES-RCS, PAES-RCS, and PAES-RCS-SD
do not suffer from overtraining and show similar performance,
thus testifying the validity of the three objective approach.

258

IEEE TRANSACTIONS ON FUZZY SYSTEMS, VOL. 25, NO. 2, APRIL 2017

AVERAGE AUC, FPR, AND TPR ON BOTH THE TRAINING AND THE TEST SETS, AVERAGE TRL, AND NUMBER OF RULES FOR THE CLASSIFIERS WITH THE HIGHEST
AUC ON THE TRAINING SET GENERATED BY IT2-PAES-RCS, PAES-RCS, PAES-RCS-SD, AND FOR THE CLASSIFIERS GENERATED BY FARC-HD, FURIA, C4.5,

AND C4.5-CS

TABLE III

AUCT r

FPRT r

TPRT r

AUCT s

FPRT s

TPRT s

TRL

#Rules

BLA

CARD

AF

ARB

IT2-PAES-RCS
PAES-RCS
PAES-RCS-SD
FARC-HD
FURIA
C4.5
C4.5-CS

IT2-PAES-RCS
PAES-RCS
PAES-RCS-SD
FARC-HD
FURIA
C4.5
C4.5-CS

IT2-PAES-RCS
PAES-RCS
PAES-RCS-SD
FARC-HD
FURIA
C4.5
C4.5-CS

IT2-PAES-RCS
PAES-RCS
PAES-RCS-SD
FARC-HD
FURIA
C4.5
C4.5-CS

COMM IT2-PAES-RCS

SL

LEN

DPKG

BAN

PAES-RCS
PAES-RCS-SD
FARC-HD
FURIA
C4.5
C4.5-CS

IT2-PAES-RCS
PAES-RCS
PAES-RCS-SD
FARC-HD
FURIA
C4.5
C4.5-CS

IT2-PAES-RCS
PAES-RCS
PAES-RCS-SD
FARC-HD
FURIA
C4.5
C4.5-CS

IT2-PAES-RCS
PAES-RCS
PAES-RCS-SD
FARC-HD
FURIA
C4.5
C4.5-CS

IT2-PAES-RCS
PAES-RCS
PAES-RCS-SD
FARC-HD
FURIA
C4.5
C4.5-CS

65.36
68.97
69.11
68.37
64.39
90.43
88.71

68.57
68.45
68.57
68.41
70.96
94.43
92.90

62.27
66.56
67.34
68.53
66.59
88.14
87.37

94.73
97.21
95.23
86.15
98.23
98.64
98.73

67.19
67.42
67.33
76.77
80.47
93.91
93.36

60.03
60.35
61.20
65.24
69.20
93.72
94.94

63.92
64.14
64.42
70.59
83.86
92.79
94.91

67.48
67.89
67.88
70.66
81.67
96.50
97.83

80.85
80.26
81.02
85.41
92.96
95.34
98.73

44.95
41.10
41.11
36.04
35.76
10.40
14.38

25.74
26.90
26.80
24.65
25.29
4.69
9.41

28.44
36.98
30.24
26.18
35.90
10.16
21.72

6.88
3.01
6.12
15.49
2.28
2.16
2.42

18.76
17.59
17.38
10.03
9.33
4.36
13.09

34.50
38.23
40.04
33.08
36.42
4.53
9.81

36.11
35.95
36.61
23.77
5.04
3.46
10.15

22.53
23.46
23.72
27.48
14.11
1.88
4.28

16.85
22.44
16.73
13.82
9.12
5.77
2.42

75.68
79.03
79.33
72.78
64.53
91.26
91.81

62.87
63.79
63.95
61.59
67.20
93.56
95.20

52.98
70.09
64.92
63.24
69.07
86.43
96.46

96.33
97.43
96.52
87.80
98.73
99.44
99.88

53.13
52.44
52.04
63.57
70.27
92.18
99.82

54.56
58.93
62.43
63.56
74.82
91.97
99.69

63.95
64.24
65.46
64.96
72.76
89.03
99.97

57.50
59.24
59.48
68.79
77.44
94.88
99.94

78.56
82.96
78.77
84.64
95.04
96.46
99.88

59.35
59.97
58.70
59.90
58.37
57.89
56.24

68.51
68.34
68.51
66.66
68.00
65.78
66.26

54.41
52.72
54.79
55.22
53.90
54.06
50.95

94.25
97.02
94.69
87.28
98.14
98.18
98.37

66.44
66.05
66.33
65.86
65.14
61.04
61.62

59.64
59.58
59.99
58.80
58.13
54.15
54.83

63.10
62.96
63.29
59.34
52.98
55.09
56.35

67.17
67.50
67.53
64.97
63.58
75.23
78.03

80.59
79.76
80.76
77.24
77.61
70.24
98.37

50.13
48.78
50.22
42.27
40.16
38.04
39.77

25.74
27.00
26.87
24.60
25.36
28.98
30.25

32.77
45.06
36.50
32.29
39.28
32.32
43.29

7.04
3.17
6.49
15.91
3.23
3.39
2.50

19.08
18.17
17.79
10.18
9.76
22.18
28.66

34.61
38.20
40.51
33.22
37.22
22.36
26.36

36.39
36.42
37.07
24.08
5.55
18.46
25.57

22.58
23.62
23.74
27.54
14.55
8.10
9.80

17.24
23.40
17.20
30.07
39.09
53.11
2.50

68.82
68.73
67.62
62.07
56.89
53.82
52.26

62.77
63.69
63.89
58.04
61.35
60.53
62.77

41.59
50.50
46.08
42.73
47.08
40.45
45.20

95.55
97.21
95.88
90.48
99.50
99.75
99.25

51.96
50.26
50.44
41.91
40.05
44.26
51.90

53.90
57.37
60.48
50.82
53.48
30.67
36.01

62.58
62.33
63.64
42.75
11.51
28.64
38.28

56.91
58.62
58.80
57.48
41.71
58.56
65.87

78.44
82.93
78.74
84.55
94.31
93.59
99.25

123.7
159.6
192.6
598.8
18.4
445.6
348.8

458.1
485.5
485.6
1852.6
22.4

33396.8
26145.2

28.8
34.0
37.1
203.0
7.6
223.8
175.4

27.4
28.8
27.7
628.0
5.6

16699.4
13073.6

364.7
501.1
592.5
768.7
31.8
508.3
412.4

51.4
49.0
47.9
35.5
60.0
78.4
32.4

115.4
145.1
167.6
313.3
73.6
2470.0
2139.6

249.4
306.1
423.4
2154.6
70.2
7962.8
7836.8

191.8
236.6
300.4
1855.9
202.4
3987.2
3776.4

94.2
102.4
138.2
1959.7
560.8
9379.2
7111.2

111.5
98.6
114.0
810.9
233.4
1932.8
273.5

33.0
38.8
41.3
264.0
11.6
255.4
207.2

21.1
20.3
20.0
16.6
26.0
40.2
17.2

27.5
30.9
35.4
118.8
20.8
1236.0
1070.8

21.9
24.1
32.2
720.6
19.2
3982.4
3301.8

42.8
50.6
59.2
644.4
49.2
1994.6
1889.2

23.4
24.4
29.5
664.3
100.4
4690.6
3556.6

28.3
24.6
30.2
331.2
41.8
966.6
17.2

ANTONELLI et al.: MULTIOBJECTIVE EVOLUTIONARY OPTIMIZATION OF TYPE-2 FUZZY RULE-BASED SYSTEMS

259

TABLE III
(Continued)

AUCT r

FPRT r

TPRT r

AUCT s

FPRT s

TPRT s

TRL

#Rules

GIV

COI

IT2-PAES-RCS
PAES-RCS
PAES-RCS-SD
FARC-HD
FURIA
C4.5
C4.5-CS

IT2-PAES-RCS
PAES-RCS
PAES-RCS-SD
FARC-HD
FURIA
C4.5
C4.5-CS

72.59
68.14
72.77
73.44
78.35
86.38
95.99

66.36
67.88
66.87
65.51
95.50
97.60
95.83

17.68
13.64
17.47
13.07
14.46
10.03
8.03

34.84
31.45
32.94
32.40
7.10
3.68
3.50

62.87
49.92
63.01
59.96
71.15
82.79
100.00

67.57
67.21
66.69
66.20
98.10
98.89
91.65

72.54
68.07
72.67
66.51
73.26
70.53
71.51

63.93
62.62
63.74
61.74
62.13
61.34
60.43

17.69
13.63
17.44
13.05
14.53
13.40
11.82

39.94
41.36
39.25
38.90
73.29
73.48
66.91

62.77
49.77
62.78
46.07
61.04
54.46
54.84

67.80
66.68
66.74
65.45
97.54
96.17
87.78

40.3
27.8
43.1
253.2
129.6
7045.6
9162.4

55.87
92.63
85.5
1304.1
510.5
596.4
772.4

19.8
14.9
19.9
87.6
19.8
3523.8
4582.2

22.1
29.9
27.3
457.6
91.4
299.2
387.2

TABLE IV

RESULTS OF THE NONPARAMETRIC STATISTICAL TESTS ON THE AUC

COMPUTED ON THE TEST SET AMONG THE CLASSIFIERS WITH THE HIGHEST
AUC ON THE TRAINING SET GENERATED BY IT2-PAES-RCS, PAES-RCS,
AND PAES-RCS-SD, AND THE CLASSIFIERS GENERATED BY FARC-HD,

FURIA, C4.5, AND C4.5-CS

To statistically verify these observations, we apply nonpara-
metric statistical tests for multiple comparisons. First, for each
approach, we generate a distribution consisting of the average
values of the AUCs on the test set. Then, we apply the Friedman
test in order to compute a ranking among the distributions [65],
and the Iman and Davenport test [66] to evaluate whether there
exist statistically relevant differences among the distributions.
If there exists a statistical difference, we apply a posthoc pro-
cedure, namely the Holm test [67]. This test allows detecting
effective statistical differences between the control approach,
i.e., the one with the lowest Friedman rank, and the remaining
approaches.

Table IV shows the results of the nonparametric statistical
tests: for each algorithm, we show the Friedman rank and the
Iman and Davenport p-value. If the p-value is lower than the

level of signicance  (in the experiments,  = 0.05), we can
reject the null hypothesis and afrm that there exist statisti-
cal differences between the multiple distributions associated
with each approach. Otherwise, no statistical difference exists
among the distributions and therefore the solutions are statis-
tically equivalent. We observe that the Iman and Davenport
statistical hypothesis of equivalence is rejected, and therefore,
statistical differences among the six approaches are detected.
Thus, we have to apply the Holm posthoc procedure consid-
ering the PAES-RCS-SD as control algorithm (associated with
the lowest rank and in bold in the table). In the part of the
table corresponding to the results obtained by the application
of the Holm posthoc procedure, the algorithms are sorted by
decreasing Friedman ranks. Index i denotes the position of the
algorithm in the sorted list (i = 1 and i = 6 correspond to the
lowest and highest Friedman ranks, respectively). The Holm
posthoc procedure computes the z-values and p-values shown
in the table: if the p-value of the algorithm in position i is
lower than the adjusted  value (/i), then the null hypothesis
is rejected.

The Holm posthoc procedure states that the AUCs on the test
set of IT2-PAES-RCS and PAES-RCS are statistically equiv-
alent to the AUC of PAES-RCS-SD. The null hypothesis is
rejected for all the other algorithms. Thus, we can conclude that
the three versions of PAES-RCS with three objectives obtain
classiers, which outperform the ones obtained by the other
approaches in terms of AUCs. In addition, this result is ob-
tained without rebalancing the datasets. Further, if we analyze
the Friedman ranks, we realize that the two algorithms with the
highest ranks are just PAES-RCS-SD and IT2-PAES-RCS. Fur-
ther, both PAES-RCS-SD and IT2-PAES-RCS obtain this result
with classiers characterized by a low number of rules. To ver-
ify this observation, we have also applied the non-parametric
statistical tests for multiple comparisons to the number of rules
and to the TRL values.

Tables V and VI show the results. Since the null hypothe-
sis is rejected for both the tests, we apply the Holm posthoc
procedure by using IT2-PAES-RCS as control algorithm. The
procedure states that, in terms of average number of rules

260

IEEE TRANSACTIONS ON FUZZY SYSTEMS, VOL. 25, NO. 2, APRIL 2017

TABLE V

RESULTS OF THE NONPARAMETRIC STATISTICAL TESTS ON THE NUMBER OF
RULES AMONG THE CLASSIFIERS WITH THE HIGHEST AUC ON THE TRAINING
SET GENERATED BY IT2-PAES-RCS, PAES-RCS, AND PAES-RCS-SD, AND
THE CLASSIFIERS GENERATED BY FARC-HD, FURIA, C4.5, AND C4.5-CS

TABLE VI

RESULTS OF THE NONPARAMETRIC STATISTICAL TESTS ON THE TRL AMONG
THE CLASSIFIERS WITH THE HIGHEST AUC ON THE TRAINING SET GENERATED
BY IT2-PAES-RCS, PAES-RCS, AND PAES-RCS-SD, AND THE CLASSIFIERS

GENERATED BY FARC-HD, FURIA, C4.5, AND C4.5-CS

(see Table V), the classiers generated by PAES-RCS, PAES-
RCS-SD, and FURIA are statistically equivalent to the ones gen-
erated by IT2-PAES-RCS. On the contrary, the null hypothesis
is rejected for FARC-HD, C4.5, and C4.5-CS. As regards TRL,
the Holm posthoc procedure concludes that the most accurate
classiers generated by IT2-PAES-RCS result to be character-
ized by an average TRL value statistically equivalent to the most
accurate classiers generated by PAES-RCS and to the classi-
ers generated by FURIA. On the contrary, the null hypothesis
is rejected for PAES-RCS-SD, FARC-HD, C4.5, and C4.5-CS.
Among the classiers used for comparison, only FURIA
shows a complexity comparable with the three versions of

MEANING OF THE ATTRIBUTES OF THE ARB DATASET

TABLE VII

Name

MoneyNess
Basis % (x10 000)

Und (x10)

Interest Ask %

Futures (T-t)

C-P % (x100)

Prot after TC (x 1 000 000)

Description

Strike Price/Underlying Index Level
Futures price minus spot index level, divided by
futures price, multiplied by 10,000
Spot index level divided by futures price,
multiplied by 10
The LIBOR ask rate for the maturity closest to the
maturity of futures contract, multiplied by 100
The nave trigger, prot after transaction costs,
divided by futures price, multiplied by 1 000 000
The difference between the call and the put prices,
divided by futures price
The nave trigger, prot after transaction costs,
divided by futures price, multiplied by 1 000 000

PAES-RCS. We have to highlight, however, that the inter-
pretability of the classiers generated by FURIA is limited
by the membership functions computed by the method. In-
deed, these membership functions are hardly describable us-
ing linguistic terms. On the contrary, thanks to the constraints
imposed on the membership function learning during the evo-
lutionary process, the partitions generated by IT2-PAES-RCS,
PAES-RCS, and PAES-RCS-SD can be easily described by lin-
guistic terms. Just to provide a glimpse of this interpretability,
we consider one of the datasets in Table I, namely ARB. Ta-
ble VII describes in detail the meaning of the attributes for the
ARB dataset. We recall that the output here is spotting arbitrage
opportunities in the LIFFE market.

Fig. 8 shows an example of partitions generated by IT2-
PAES-RCS for one of the classiers with the highest AUC on
the training set for the ARB. Here, only six out of seven attributes
are shown since one of the attributes was not used in the nal rule
base. We can observe that, although the evolutionary process has
tuned the IT2 fuzzy sets on the specic dataset, the partitions of
the different attributes result to be easily interpretable.

As regards the interpretability of the rules, Fig. 9 shows the
rule base of the classier whose data base is shown in Fig. 8.
Here, we do not show the dont care conditions, since they do
not contribute to the inference process and penalize the inter-
pretability of the rule base. The expert can deduce interesting
knowledge from the rules of the classier. Indeed, he/she can,
for instance, discover that intermediate values of C-P (C-P is M)
lead to conclude that the class is Arbitrage Opportunity. On the
other hand, very high values of Futures (Futures is VH) allow
inferring that the class is non-Arbitrage Opportunity.

The nonparametric statistical tests for multiple comparisons
have shown that the classiers generated by IT2-PAES-RCS,
PAES-RCS, and PAES-RCS-SD achieve similar AUC on the
test set and have similar complexity, at least in terms of number
of rules. We observe, however, that IT2-PAES-RCS is charac-
terized by the minimum Friedman rank in both Tables V and VI.
Thus, we decided to perform a statistical analysis between IT2-
PAES-RCS and each of the other two approaches separately.
We applied the Wilcoxon signed-rank test for pairwise com-
parison [68], considering IT2-PAES-RCS as control algorithm,

ANTONELLI et al.: MULTIOBJECTIVE EVOLUTIONARY OPTIMIZATION OF TYPE-2 FUZZY RULE-BASED SYSTEMS

261

Fig. 8. Example of partitions generated by IT2-PAES-RCS for one of the classiers with the highest AUC on the training set for the dataset ARB.

Fig. 9. Rule base of the classier whose data base is shown in Fig. 8.

TABLE VIII

RESULTS OF THE WILCOXON SIGNED-RANK TEST ON AUC, TRL, AND

NUMBER OF RULES AMONG THE CLASSIFIERS WITH THE HIGHEST AUC ON

THE TRAINING SET GENERATED BY IT2-PAES-RCS, PAES-RCS, AND

PAES-RCS-SD

AU CT s

IT2-PAES-RCS versus
PAES-RCS
IT2-PAES-RCS versus
PAES-RCS-SD
TRL

IT2-PAES-RCS versus
PAES-RCS
IT2-PAES-RCS versus
PAES-RCS-SD
#Rules

IT2-PAES-RCS versus
PAES-RCS
IT2-PAES-RCS versus
PAES-RCS-SD

R+

46.0

15.5

R+

58.0

63.0

R+

58.0

63.0

R-

p-value

Hypothesis (alpha = 0.05)

20.0

39.5

0.230

1

Not Rejected

Not Rejected

R-

8.0

3.0

R-

8.0

3.0

p-value

Hypothesis(alpha = 0.05)

0.023

0.006

Rejected

Rejected

p-value

Hypothesis(alpha = 0.05)

0.023

0.006

Rejected

Rejected

to the distributions of AUCs calculated on the test set, average
number of rules, and average TRL.

Table VIII shows the results of the test. The null hypoth-
esis is not rejected for the AUC computed on the test set,
but is rejected for the average number of rules and average
TRL. We can conclude that IT2-PAES-RCS generated clas-
siers that achieve the same accuracy in terms of AUC as
PAES-RCS and PAES-RCS-SD, but with a lower number of
rules and a lower TRL. Thus, the classiers generated by
IT2-PAES-RCS result to be less complex and, therefore, more
interpretable.

V. CONCLUSION

Financial data are often strongly unbalanced and charac-
terized by a high level of uncertainty. In this paper, we have
proposed to deal with nancial data classication by adopting
rule-based classiers generated by an MOEA. These classiers
have proved to be very effective in terms of accuracy. Further,

262

IEEE TRANSACTIONS ON FUZZY SYSTEMS, VOL. 25, NO. 2, APRIL 2017

they are generally characterized by a low number of rules and
TRL, and a good integrity of the partitions, thus making them
very interpretable. Interpretability is considered essential in the
nancial context, since the comprehension of how inputs and
output are related to each other is crucial to take both operative
and strategic decisions.

We have extended PAES-RCS, an MOEA-based approach to
learn concurrently the rule and data bases of FRBCs. In order
to cope with unbalanced datasets, we have split the accuracy
into two objectives, namely TPR and FPR, and we have used an
approach denoted as scaled dominance to give minority classes
a fair chance when competing with a majority class. Further, we
have coped with uncertainty by adopting IT2 fuzzy sets rather
than type-1 fuzzy sets. This has required using a different in-
ference mechanism. We have tested the three improvements on
11 nancial datasets and compared the results with the ones
obtained by the FRBCs FARC-HD and FURIA, the classical
C4.5 decision tree algorithm and its cost-sensitive version. Us-
ing nonparametric statistical tests, we have shown that the three
improvements allow generating classiers, which outperform
the comparison approaches both in terms of accuracy, com-
puted as AUC, and complexity, computed as number of rules.
Finally, the extension of PAES-RCS, which integrates the three
improvements, has proved to achieve high accuracy with, on
average, the lowest number of rules and TRL.

REFERENCES

[1] The Regulatory Opportunity

(2014).
[Online]. Available: http://butleranalytics.com/regulatory-opportunity-
nancial-services/

in Financial Services,

[2] Predictive Models - Risks and Benets, (2014). [Online]. Available:

http://butleranalytics.com/predictive-models-risks-benets/

[3] Predictive Model Management Strategy, (2014). [Online]. Available:

http://butleranalytics.com/nancial-regulation-predictive-models/

[4] A. Garcia-Almanza and E. Tsang, Forecasting stock prices using genetic
programming and chance discovery, presented at the 12th Int. Conf.
Comput. Econ. Finance, Limassol, Cyprus, Jun. 2224, 2006.

[5] A. Garcia-Almanza and E. Tsang, Evolving decision rules to predict
investment opportunities, Int. J. Autom. Comput., vol. 5, no. 1, pp. 22
31, 2008.

[6] A. Garcia-Almanza, New classication methods for gathering patterns in
the context of genetic programming, Ph.D. dissertation, Dept. Comput.
Electron. Syst., Univ. Essex, Colchester, U.K., 2008.

[7] L. Breiman, Random Forests, Mach. Learn., vol. 45, no. 1, pp. 532,

2001.

[8] J. Casillas, O. Cordon, F. Herrera, L. Magdalena, Eds., Interpretability

Issues in Fuzzy Modelling. New York, NY, USA: Springer, 2003.

[9] M. Setnes and H. Roubos, GA-fuzzy modelling and classication: Com-
plexity and performance, IEEE Trans. Fuzzy Syst., vol. 8, no. 5, pp. 509
522, Oct. 2000.

[10] H. Ishibuchi and T. Yamamoto, Interpretability issues in fuzzy genetic-
based machine learning for linguistic modelling, in Modelling with
Words (Lecture Notes in Computer Science), vol. 2873. Berlin, Germany:
Springer-Verlag, 2003, pp. 209228.

[11] H. Ishibuchi, T. Nakashima, and M. Nii, Classication and Modeling
with Linguistic Information Granules: Advanced Approaches to Linguistic
Data Mining. Berlin, Germany: Springer-Verlag, 2004.

[12] P. Ducange and F. Marcelloni, Multi-objective evolutionary fuzzy sys-

tems, in Proc. 9th Int. Workshop Fuzzy Logic Appl., 2011, pp. 8390.

[13] M. Fazzolari, R. Alcala, Y. Nojima, H. Ishibuchi, and F. Herrera, A review
of the application of multiobjective evolutionary fuzzy systems: Current
status and further directions, IEEE Trans. Fuzzy Syst., vol. 21, no. 1,
pp. 4565, Feb. 2013.

[14] P. Melin and O. Castillo, A review on type-2 fuzzy logic applications
in clustering, classication and pattern recognition, Appl. Soft Comput.,
vol. 21, pp. 568577, 2014.

[15] C. Glackin, L. Maguire, R. McIvor, P. Humphreys, and P. Herman, A
comparison of fuzzy strategies for corporate acquisition analysis, Fuzzy
Sets Syst., vol. 159, no. 18, pp. 20392056, 2007.

[16] D. Bernardo, H. Hagras, and E. Tsang, A genetic type-2 fuzzy logic based
system for the generation of summarised linguistic predictive models for
nancial applications, Soft Comput., vol. 17, no. 12, pp. 21852201,
2013.

[17] J.A Sanz, D. Bernardo, F. Herrera, H. Bustince, and H. Hagras, A com-
pact evolutionary interval-valued fuzzy rule-based classication system
for the modeling and prediction of real-world nancial applications with
imbalanced data, IEEE Trans. Fuzzy Syst., vol. 23, no. 4, pp. 973990,
Aug. 2015.

[18] D. Wu and W. Tan, Genetic learning and performance evaluation of
interval type-2 fuzzy logic controllers, Eng. Appl. Artif. Intell., vol. 19,
no. 8, pp. 819841, 2006.

[19] R. Martnez-Soto, O. Castillo, L. T. Aguilar, and A. R. Daz, A hybrid
optimization method with PSO and GA to automatically design type-1
and type-2 fuzzy logic controllers, Int. J. Mach. Learn. Cybern., vol. 6,
no. 2, pp. 175196, 2015.

[20] O. Linda and M. Manic, Uncertainity-robust design of interval type-2
fuzzy logic controller for delta parallel robot, IEEE Trans. Ind. Informat.,
vol. 7, no. 4, pp. 661670, Nov. 2011.

[21] M. Almaraahi, R. John, and S. Ahmadi, Learning of type-2 fuzzy logic
systems by simulated annealing with adaptive step size, in Electrical
Engineering and Intelligent Systems (ser. Lecture Notes in Electrical En-
gineering), vol. 130. Berlin, Germany: Springer-Verlag, 2013, pp. 5364.
[22] T. Kumbasar and H. Hagras, Big bang-big crunch optimization based
Interval type-2 fuzzy PID cascade controller design strategy, Inf. Sci.,
vol. 282, pp. 277295, 2014.

[23] J. Mendel, H. Hagras, W-W. Tan, W. Melek, and H. Ying, Introduction
to Type-2 Fuzzy Logic Control: Theory and Applications. New York, NY,
USA: Wiley/IEEE Press, 2014.

[24] G. G. Sundarkumar and V. Ravi, A novel hybrid undersampling method
for mining unbalanced datasets in banking and insurance, Eng. Appl.
Artif. Intell., vol. 36, pp. 368377, 2015.

[25] M. Antonelli, P. Ducange, and F. Marcelloni, Multi-objective evolution-
ary rule and condition selection for designing fuzzy rule-based classiers,
in Proc. IEEE Int. Conf. Fuzzy Syst., Brisbane, Australia, Jun. 1015, 2012,
pp. 794800.

[26] M. Antonelli, P. Ducange, and F. Marcelloni, A fast and efcient multi-
objective evolutionary learning scheme for fuzzy rule-based classiers,
Inf. Sci., vol. 283, pp. 3654, 2014.

[27] M. Antonelli, P. Ducange, and F. Marcelloni, An experimental study
on evolutionary fuzzy classiers designed for managing imbalanced
datasets, Neurocomput., vol. 146, pp. 125136, 2014.

[28] J. Alcala-Fdez, R. Alcala, and F. Herrera, A fuzzy association rule-
based classication model for high-dimensional problems with genetic
rule selection and lateral tuning, IEEE Trans. Fuzzy Syst., vol. 19, no. 5,
pp. 857872, Oct. 2011.

[29] J. Huhn and E. Hullermeier, FURIA: An algorithm for unordered fuzzy
rule induction, Data Mining Knowl. Discovery, vol. 19, no. 3, pp. 293
319, 2009.

[30] J. Quinlan, C4.5: Programs for Machine Learning. San Mateo, CA, USA:

Morgan Kauffman, 1993.

[31] K. M. Ting, An instance-weighting method to induce cost-sensitive trees,
IEEE Trans. Knowl. Data Eng., vol. 14, no. 3, pp. 659665, May/Jun.
2002.

[32] Q. Liang and J. M. Mendel, Interval type-2 fuzzy logic systems: Theory
and design, IEEE Trans. Fuzzy Syst., vol. 8, no. 5, pp. 535550, Oct.
2000.

[33] D. Bernardo, H. Hagras, and E. Tsang, An interval type-2 fuzzy logic
system for the modelling and prediction of nancial applications, pre-
sented at the Int. Conf. Auton. Intell. Syst., Aveiro, Portugal, Jun. 2527,
2012.

[34] D. Bernardo, H. Hagras, and E. Tsang, An interval type-2 fuzzy logic
based system for model generation and summarization of arbitrage op-
portunities in stock markets, presented at the U.K. Workshop Comput.
Intell., Edinburgh, U.K., Sep. 57, 2012.

[35] D. Bernardo, H. Hagras, and E. Tsang, A genetic type-2 fuzzy logic based
system for nancial applications modelling and prediction, presented
at the Proc. IEEE Int. Conf. Fuzzy Syst., Hyderabad, India, Jul. 710,
2013.

[36] A. Zhou, B-Y. Qu, H. Li, S-Z. Zhao, P. N. Suganthan, and Q. Zhang,
Multiobjective evolutionary algorithms: A survey of the state of the art,
Swarm Evol. Comput., vol. 1, no. 1, pp. 3249, 2011.

ANTONELLI et al.: MULTIOBJECTIVE EVOLUTIONARY OPTIMIZATION OF TYPE-2 FUZZY RULE-BASED SYSTEMS

263

[37] P. Ducange, B. Lazzerini, and F. Marcelloni, Multi-objective genetic
fuzzy classiers for imbalanced and cost-sensitive datasets, Soft Comput.,
vol. 14, no. 10, pp. 713728, 2010.

[38] F. Herrera, Genetic fuzzy systems: Taxonomy, current research trends

and prospects, Evol. Intell., vol. 1, no. 1, pp. 2746, 2008.

[39] J. M. Alonso and L. Magdalena, Editorial: Special issue on interpretable

fuzzy systems, Inf. Sci., vol. 181, no. 20, pp. 43314339, 2011.

[40] M. J. Gacto, R. Alcala, and F. Herrera, Interpretability of linguistic fuzzy
rule-based systems: An overview of interpretability measures, Inf. Sci.,
vol. 128, no. 20, pp. 43404360, 2011.

[41] M. Cococcioni, P. Ducange, B. Lazzerini, and F. Marcelloni, A Pareto-
based multi-objective evolutionary approach to the identication of mam-
dani fuzzy systems, Soft Comput., vol. 11, no. 11, pp. 10131031,
2007.

[42] A. Botta, B. Lazzerini, F. Marcelloni, and D. Stefanescu, Context adap-
tation of fuzzy systems through a multi-objective evolutionary approach
based on a novel interpretability index, Soft Comput., vol. 13, no. 5,
pp. 437449, 2009.

[43] R. Alcala, P. Ducange, F. Herrera, B. Lazzerini, and F. Marcelloni, A
multi-objective evolutionary approach to concurrently learn rule and data
bases of linguistic fuzzy rule-based systems, IEEE Trans. Fuzzy Syst.,
vol. 17, no. 5, pp. 11061122, Oct. 2009.

[44] M. Antonelli, P. Ducange, B. Lazzerini,

and F. Marcelloni,
Multi-objective evolutionary learning of granularity, membership func-
tion parameters and rules of Mamdani fuzzy systems, Evol. Intell., vol. 2,
no. 12, pp. 2137, 2009.

[45] J. Casillas, P. Martinez, and A. D. Benitez, Learning consistent, complete
and compact sets of fuzzy rules in conjunctive normal form for regression
problems, Soft Comput., vol. 13, no. 5, pp. 451465, 2009.

[46] P. Pulkkinen and H. Koivisto, A dynamically constrained multiobjective
genetic fuzzy system for regression problems, IEEE Trans. Fuzzy Syst.,
vol. 18, no. 1, pp. 161177, Feb. 2010.

[47] M. Antonelli, P. Ducange, B. Lazzerini, and F. Marcelloni, Learning
concurrently data and rule bases of Mamdani fuzzy rule-based systems by
exploiting a novel interpretability index, Soft Comput., vol. 15, no. 10,
pp. 19811998, 2011.

[48] M. Antonelli, P. Ducange, B. Lazzerini, and F. Marcelloni, Learning
knowledge bases of multi-objective evolutionary fuzzy systems by simul-
taneously optimizing accuracy, complexity and partition integrity, Soft
Comput., vol. 15, no. 12, pp. 23352354, 2011.

[49] M. J. Gacto, R. Alcala, and F. Herrera, Integration of an index to preserve
the semantic interpretability in the multi-objective evolutionary rule se-
lection and tuning of linguistic fuzzy systems, IEEE Trans. Fuzzy Syst.,
vol. 18, no. 3, pp. 515531, Jun. 2010.

[50] R. Alcala, M. J. Gacto, and F. Herrera, A fast and scalable multiobjective
genetic fuzzy system for linguistic fuzzy modeling in high-dimensional
regression problems, IEEE Trans. Fuzzy Syst., vol. 19, no. 4, pp. 666681,
Aug. 2011.

[51] M. Antonelli, P. Ducange, and F. Marcelloni, Genetic training instance
selection in multi-objective evolutionary fuzzy systems: A co-evolutionary
approach, IEEE Trans. Fuzzy Syst., vol. 20, no. 2, pp. 276290, Apr. 2012.
[52] H. Ishibuchi, T. Murata, and I. B. Turksen, Single-objective and two
objective genetic algorithms for selecting linguistic rules for pattern
classication problems, Fuzzy Sets Syst., vol. 89, no. 2, pp. 135150,
1997.

[53] O. Cordon, M. J. del Jesus, J. Casillas, F. Herrera, L. Magdalena, and P.
Villar, A multiobjective genetic learning process for joint feature selec-
tion and granularity and context learning in fuzzy rule-based classica-
tion systems, in Interpretability Issues in Fuzzy Modeling, J. Casillas,
F. Herrera, O. Cordoon, and L. Magdalena, Eds. Secaucus, NJ, USA:
Springer-Verlag, 2003, pp. 7999.

[54] H. Ishibuchi and T. Yamamoto, Fuzzy rule selection by multi-objective
genetic local search algorithms and rule evaluation measures in data min-
ing, Fuzzy Sets Syst., vol. 141, pp. 5988, 2004.

[55] H. Ishibuchi and Y. Nojima, Analysis of interpretability-accuracy tradeoff
of fuzzy systems by multiobjective fuzzy genetics-based machine learn-
ing, Int. J. Approx. Reason., vol. 44, no. 1, pp. 431, 2007.

[56] R. Alcala, Y. Nojima, F. Herrera, and H. Ishibuchi, Multiobjective genetic
fuzzy rule selection of single granularity-based fuzzy classication rules
and its interaction with the lateral tuning of membership functions, Soft
Comput., vol. 15, no. 12, pp. 23032318, 2011.

[57] P. Pulkkinen and H. Koivisto, Fuzzy classier identication using de-
cision tree and multiobjective evolutionary algorithms, Int. J. Approx.
Reason., vol. 48, pp. 526543, 2008.

[58] K. Trawinski, O. Cordon, and A. Quirin, A Study on the use of multiob-
jective genetic algorithms for classier selection in FURIA-based fuzzy
multiclassiers, Int. J. Comput. Intell. Syst., vol. 5, no. 2, pp. 231253,
2012.

[59] O. Cordon, M. J. del Jesus, and F. Herrera, A proposal on reasoning meth-
ods in fuzzy rule-based classication systems, Int. J. Approx. Reason.,
vol. 20, no. 1, pp. 2145, 1999.

[60] W. W. Cohen, Fast effective rule induction, in Proc. 12th Int. Conf.

Mach. Learning, 1995, pp. 115123.

[61] J. R. Quinlan, Boosting, bagging, and C4.5, in Proc. 13th Nat. Conf.

Artif. Intell., 1996, vol. 1, pp. 725730.

[62] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer, Smote:
Synthetic minority over-sampling technique, J. Artif. Intell. Res., vol. 16,
pp. 321357, 2002.

[63] J. Alcala-Fdez, A. Fernandez, J. Luengo, J. Derrac, and S. Garcia, KEEL
data-mining software tool: Data set repository, integration of algorithms
and experimental analysis framework, Multiple-Valued Log. Soft Com-
put., vols. 2/3, pp. 255287, 2011.

[64] T. Fawcett, An introduction to ROC analysis, Pattern Recog. Lett.,

vol. 27, no. 8, pp. 861874, 2006.

[65] M. Friedman, The use of ranks to avoid the assumption of normality
implicit in the analysis of variance, J. Amer. Stat. Assoc., vol. 32, pp. 675
701, 1937.

[66] R. L. Iman and J. H. Davenport, Approximations of the critical region
of the Friedman statistic, Commun. Statist. A, Theory Methods, vol. 9,
pp. 571595, 1980.

[67] S. Holm, A simple sequentially rejective multiple test procedure, Scand.

J. Statist., vol. 6, pp. 6570, 1979.

[68] D. J. Sheskin, Handbook of Parametric and Nonparametric Statisti-
cal Procedures, 4th ed. London, U.K.: Chapman & Hall/CRC Press,
2007.

Michela Antonelli received the M.Sc. degree in com-
puter engineering and the Ph.D. degree in information
engineering from the University of Pisa, Pisa, Italy,
in 2003 and 2007, respectively.

She was a Research Fellow with the Computa-
tional Intelligence Group, Department of Information
Engineering, University of Pisa, from 2008 to 2014.
She is currently a Research Associate with the Cen-
tre for Medical Image Computing, University College
London, London, U.K. Her main research interests in-
clude computational intelligence, with particular em-

phasis to fuzzy systems and multiobjective evolutionary algorithms.

Dario Bernardo received the B.Sc. and M.Sc. de-
grees in computer engineering for enterprise man-
agement from the University of Pisa, Pisa, Italy, and
another M.Sc. degree in computational and software
techniques in engineering from Craneld University,
Craneld, U.K. He is currently working toward the
Ph.D. degree in computer science with the University
of Essex, Colchester, U.K., as a Knowledge Partner-
ship Associate.

He is currently a Data Scientist working in Lon-
don, U.K., in the eld of predictive analytics in -
nance. His major research interests include computational intelligence, machine
learning, type-2 fuzzy systems, fuzzy logic, genetic algorithms, and evolution-
ary computation. His research interests also include big data analytics, algorithm
scalability, and optimization.

264

IEEE TRANSACTIONS ON FUZZY SYSTEMS, VOL. 25, NO. 2, APRIL 2017

Hani Hagras (M03SM05F13) received the
B.Sc. and M.Sc. degrees in electrical engineering
from Alexandria University, Alexandria, Egypt, and
the Ph.D. degree in computer science from the Uni-
versity of Essex, Colchester, U.K.

He is currently a Professor with the School of
Computer Science and Electronic Engineering, Di-
rector of the Computational Intelligence Centre, and
the Head of the Fuzzy Systems Research Group with
the University of Essex. His major research interests
include computational intelligence, notably type-2
fuzzy systems, fuzzy logic, neural networks, genetic algorithms, and evolu-
tionary computation. His research interests also include ambient intelligence,
pervasive computing, and intelligent buildings. He is also interested in embed-
ded agents, robotics, and intelligent control. He has authored more than 300
papers in international journals, conferences, and books.

Dr. Hagras is a Fellow of the Institution of Engineering and Technology.
He was the Chair of IEEE Computational Intelligence Society (CIS) Senior
Members Subcommittee. He has received numerous prestigious international
awards where most recently he was awarded by the IEEE CIS the 2013 Out-
standing Paper Award in the IEEE TRANSACTIONS ON FUZZY SYSTEMS. He
also received the 2006 Outstanding Paper Award in the IEEE TRANSACTIONS
ON FUZZY SYSTEMS. He is an Associate Editor of the IEEE TRANSACTIONS ON
FUZZY SYSTEMS. He is also an Associate Editor of the International Journal of
Robotics and Automation, the Journal of Cognitive Computation, and the Jour-
nal of Ambient Computing and Intelligence. He is a member of the IEEE CIS
Fuzzy Systems Technical Committee and IEEE CIS Conference Committee. He
chaired several international conferences where he will act as the Programme
Chair of the 2017 IEEE International Conference on Fuzzy Systems, Naples,
Italy, July 2017, and he served as the General Co-Chair of the 2007 IEEE Inter-
national Conference on Fuzzy Systems, London, U.K.

Francesco Marcelloni (M06) received the Laurea
degree in electronics engineering and the Ph.D. de-
gree in computer engineering from the University of
Pisa, Pisa, Italy, in 1991 and 1996, respectively.

He is currently a Full Professor with the Depart-
ment of Information Engineering, University of Pisa.
He has co-founded the Computational Intelligence
Group in 2002 and is the Founder and Head of the
Competence Centre on MObile Value Added Ser-
vices (MOVAS), both with the Department of In-
formation Engineering, University of Pisa. His main
research interests include fuzzy classiers for big data, multiobjective evolu-
tionary algorithms, genetic fuzzy systems, fuzzy clustering algorithms, pattern
recognition, signal analysis, neural networks, mobile information systems, and
data compression and aggregation in wireless sensor networks. He has coedited
three volumes, four journal special issues, and is (co)author of a book and of
more than 200 papers in international journals, books, and conference proceed-
ings. He has been TPC co-chair, general co-chair, and tutorial chair of some
international conferences and has held invited talks in a number of events.

Dr. Marcelloni is an Associate Editor of Information Sciences (Elsevier) and
Soft Computing (Springer). He is on the Editorial Board of a number of other
international journals.

